{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing and using scikit-learn machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file lists the machine learning algorithms included in scikit-learn and classifies the Wisconsin breast cancer dataset using these algorithms. 5 of these algorithms was optimized using the RandomizedSearchCV method.  The optimized algorithms are:\n",
    "\n",
    "* RandomForestClassifier\n",
    "* ExtraTreeClassifier\n",
    "* SVC\n",
    "* GradientBoostingClassifier\n",
    "* DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing of required libraries for listing Sk-learn estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n",
      "BaggingClassifier <class 'sklearn.ensemble._bagging.BaggingClassifier'>\n",
      "BernoulliNB <class 'sklearn.naive_bayes.BernoulliNB'>\n",
      "CalibratedClassifierCV <class 'sklearn.calibration.CalibratedClassifierCV'>\n",
      "CategoricalNB <class 'sklearn.naive_bayes.CategoricalNB'>\n",
      "ClassifierChain <class 'sklearn.multioutput.ClassifierChain'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.multioutput.ClassifierChain'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'base_estimator'\n",
      "ComplementNB <class 'sklearn.naive_bayes.ComplementNB'>\n",
      "DecisionTreeClassifier <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "DummyClassifier <class 'sklearn.dummy.DummyClassifier'>\n",
      "ExtraTreeClassifier <class 'sklearn.tree._classes.ExtraTreeClassifier'>\n",
      "ExtraTreesClassifier <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>\n",
      "GaussianNB <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "GaussianProcessClassifier <class 'sklearn.gaussian_process._gpc.GaussianProcessClassifier'>\n",
      "GradientBoostingClassifier <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "HistGradientBoostingClassifier <class 'sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier'>\n",
      "KNeighborsClassifier <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "LabelPropagation <class 'sklearn.semi_supervised._label_propagation.LabelPropagation'>\n",
      "LabelSpreading <class 'sklearn.semi_supervised._label_propagation.LabelSpreading'>\n",
      "LinearDiscriminantAnalysis <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
      "LinearSVC <class 'sklearn.svm._classes.LinearSVC'>\n",
      "LogisticRegression <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "LogisticRegressionCV <class 'sklearn.linear_model._logistic.LogisticRegressionCV'>\n",
      "MLPClassifier <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "MultiOutputClassifier <class 'sklearn.multioutput.MultiOutputClassifier'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.multioutput.MultiOutputClassifier'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "MultinomialNB <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "NearestCentroid <class 'sklearn.neighbors._nearest_centroid.NearestCentroid'>\n",
      "NuSVC <class 'sklearn.svm._classes.NuSVC'>\n",
      "OneVsOneClassifier <class 'sklearn.multiclass.OneVsOneClassifier'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.multiclass.OneVsOneClassifier'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "OneVsRestClassifier <class 'sklearn.multiclass.OneVsRestClassifier'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.multiclass.OneVsRestClassifier'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "OutputCodeClassifier <class 'sklearn.multiclass.OutputCodeClassifier'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.multiclass.OutputCodeClassifier'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "PassiveAggressiveClassifier <class 'sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier'>\n",
      "Perceptron <class 'sklearn.linear_model._perceptron.Perceptron'>\n",
      "QuadraticDiscriminantAnalysis <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>\n",
      "RadiusNeighborsClassifier <class 'sklearn.neighbors._classification.RadiusNeighborsClassifier'>\n",
      "RandomForestClassifier <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "RidgeClassifier <class 'sklearn.linear_model._ridge.RidgeClassifier'>\n",
      "RidgeClassifierCV <class 'sklearn.linear_model._ridge.RidgeClassifierCV'>\n",
      "SGDClassifier <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "SVC <class 'sklearn.svm._classes.SVC'>\n",
      "StackingClassifier <class 'sklearn.ensemble._stacking.StackingClassifier'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.ensemble._stacking.StackingClassifier'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'estimators'\n",
      "VotingClassifier <class 'sklearn.ensemble._voting.VotingClassifier'>\n",
      "\n",
      "Unable to import   ------------------> <class 'sklearn.ensemble._voting.VotingClassifier'> \n",
      "\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "estimators = all_estimators(type_filter='classifier')\n",
    "\n",
    "estimator_list = []\n",
    "for number, estimator in estimators:\n",
    "    print(number, estimator)\n",
    "    try:\n",
    "        clf = estimator()\n",
    "        estimator_list.append(clf)\n",
    "    except Exception as e:\n",
    "        print('\\nUnable to import   ------------------>', estimator,\"\\n\")\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list of obtained algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                    n_estimators=50, random_state=None),\n",
       " BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                   max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                   n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                   warm_start=False),\n",
       " BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       " CalibratedClassifierCV(base_estimator=None, cv=None, method='sigmoid'),\n",
       " CategoricalNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best'),\n",
       " DummyClassifier(constant=None, random_state=None, strategy='warn'),\n",
       " ExtraTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, random_state=None,\n",
       "                     splitter='random'),\n",
       " ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                      criterion='gini', max_depth=None, max_features='auto',\n",
       "                      max_leaf_nodes=None, max_samples=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False),\n",
       " GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " GaussianProcessClassifier(copy_X_train=True, kernel=None, max_iter_predict=100,\n",
       "                           multi_class='one_vs_rest', n_jobs=None,\n",
       "                           n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
       "                           random_state=None, warm_start=False),\n",
       " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " HistGradientBoostingClassifier(l2_regularization=0.0, learning_rate=0.1,\n",
       "                                loss='auto', max_bins=255, max_depth=None,\n",
       "                                max_iter=100, max_leaf_nodes=31,\n",
       "                                min_samples_leaf=20, n_iter_no_change=None,\n",
       "                                random_state=None, scoring=None, tol=1e-07,\n",
       "                                validation_fraction=0.1, verbose=0,\n",
       "                                warm_start=False),\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                      weights='uniform'),\n",
       " LabelPropagation(gamma=20, kernel='rbf', max_iter=1000, n_jobs=None,\n",
       "                  n_neighbors=7, tol=0.001),\n",
       " LabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=30, n_jobs=None,\n",
       "                n_neighbors=7, tol=0.001),\n",
       " LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                            solver='svd', store_covariance=False, tol=0.0001),\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                      max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                      penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                      solver='lbfgs', tol=0.0001, verbose=0),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "               power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "               warm_start=False),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " NearestCentroid(metric='euclidean', shrink_threshold=None),\n",
       " NuSVC(break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "       max_iter=-1, nu=0.5, probability=False, random_state=None, shrinking=True,\n",
       "       tol=0.001, verbose=False),\n",
       " PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                             early_stopping=False, fit_intercept=True,\n",
       "                             loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                             n_jobs=None, random_state=None, shuffle=True,\n",
       "                             tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False),\n",
       " Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "            fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "            penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "            validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "                               store_covariance=False, tol=0.0001),\n",
       " RadiusNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                           metric_params=None, n_jobs=None, outlier_label=None,\n",
       "                           p=2, radius=1.0, weights='uniform'),\n",
       " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                 max_iter=None, normalize=False, random_state=None,\n",
       "                 solver='auto', tol=0.001),\n",
       " RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]), class_weight=None, cv=None,\n",
       "                   fit_intercept=True, normalize=False, scoring=None,\n",
       "                   store_cv_values=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing required libraries for using this MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm.classes import OneClassSVM\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.linear_model.ridge import RidgeClassifierCV\n",
    "from sklearn.linear_model.ridge import RidgeClassifier\n",
    "from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier    \n",
    "from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import  ComplementNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "\n",
    "from sklearn import datasets\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import randint as sp_randFloat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the breast cancer wisconsin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer=datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "X_cancer = cancer.data\n",
    "y_cancer= cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  List of MLs in dictinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_list={\"ExtraTreeClassifier\":ExtraTreeClassifier(),\n",
    "\"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
    "\"OneClassSVM\":OneClassSVM(),\n",
    "\"MLPClassifier\":MLPClassifier(),\n",
    "\"ComplementNB\":ComplementNB(),\n",
    "\"DummyClassifier\":DummyClassifier(),         \n",
    "\"RadiusNeighborsClassifier\":RadiusNeighborsClassifier(),\n",
    "\"KNeighborsClassifier\":KNeighborsClassifier(),\n",
    "\"ClassifierChain\":ClassifierChain(base_estimator=DecisionTreeClassifier()),\n",
    "\"MultiOutputClassifier\":MultiOutputClassifier(estimator=DecisionTreeClassifier()),\n",
    "\"OutputCodeClassifier\":OutputCodeClassifier(estimator=DecisionTreeClassifier()),\n",
    "\"OneVsOneClassifier\":OneVsOneClassifier(estimator=DecisionTreeClassifier()),\n",
    "\"OneVsRestClassifier\":OneVsRestClassifier(estimator=DecisionTreeClassifier()),\n",
    "\"SGDClassifier\":SGDClassifier(),\n",
    "\"RidgeClassifierCV\":RidgeClassifierCV(),\n",
    "\"RidgeClassifier\":RidgeClassifier(),\n",
    "\"PassiveAggressiveClassifier    \":PassiveAggressiveClassifier    (),\n",
    "\"GaussianProcessClassifier\":GaussianProcessClassifier(),\n",
    "\"AdaBoostClassifier\":AdaBoostClassifier(),\n",
    "\"GradientBoostingClassifier\":GradientBoostingClassifier(),\n",
    "\"BaggingClassifier\":BaggingClassifier(),\n",
    "\"ExtraTreesClassifier\":ExtraTreesClassifier(),\n",
    "\"RandomForestClassifier\":RandomForestClassifier(),\n",
    "\"BernoulliNB\":BernoulliNB(),\n",
    "\"CalibratedClassifierCV\":CalibratedClassifierCV(),\n",
    "\"GaussianNB\":GaussianNB(),\n",
    "\"LabelPropagation\":LabelPropagation(),\n",
    "\"LabelSpreading\":LabelSpreading(),\n",
    "\"LinearDiscriminantAnalysis\":LinearDiscriminantAnalysis(),\n",
    "\"LinearSVC\":LinearSVC(),\n",
    "\"LogisticRegression\":LogisticRegression(),\n",
    "\"LogisticRegressionCV\":LogisticRegressionCV(),\n",
    "\"MultinomialNB  \":MultinomialNB  (),\n",
    "\"NearestCentroid\":NearestCentroid(),\n",
    "\"NuSVC\":NuSVC(),\n",
    "\"Perceptron\":Perceptron(),\n",
    "\"QuadraticDiscriminantAnalysis\":QuadraticDiscriminantAnalysis(),\n",
    "\"SVC\":SVC(),\n",
    "\"HistGradientBoostingClassifier\":HistGradientBoostingClassifier(),\n",
    "\"CategoricalNB\" : CategoricalNB()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model                                  F1 Score           Accuracy          Training Time         Testing Time      \n",
      "|____________________|                   ____________________ ____________________ ____________________ ____________________\n",
      "ExtraTreeClassifier                      0.92614              0.93007              0.001                0.0                 \n",
      "DecisionTreeClassifier                   0.89092              0.8951               0.00698              0.0                 \n",
      "OneClassSVM                              0.20513              0.33566              0.012                0.00196             \n",
      "MLPClassifier                            0.89586              0.9021               0.46438              0.001               \n",
      "ComplementNB                             0.89024              0.9021               0.001                0.00101             \n",
      "DummyClassifier                          0.55368              0.58042              0.001                0.0                 \n",
      "RadiusNeighborsClassifier                Error                Error               \n",
      "KNeighborsClassifier                     0.9328               0.93706              0.001                0.00698             \n",
      "ClassifierChain                          Error                Error               \n",
      "MultiOutputClassifier                    Error                Error               \n",
      "OutputCodeClassifier                     0.27041              0.37063              0.001                0.00101             \n",
      "OneVsOneClassifier                       0.88398              0.88811              0.00598              0.0                 \n",
      "OneVsRestClassifier                      0.90491              0.90909              0.00598              0.001               \n",
      "SGDClassifier                            0.93905              0.94406              0.00199              0.0                 \n",
      "RidgeClassifierCV                        0.95387              0.95804              0.00399              0.0                 \n",
      "RidgeClassifier                          0.95387              0.95804              0.00299              0.0                 \n",
      "PassiveAggressiveClassifier              0.75481              0.75524              0.001                0.001               \n",
      "GaussianProcessClassifier                0.91787              0.92308              0.08777              0.00997             \n",
      "AdaBoostClassifier                       0.9776               0.97902              0.13169              0.00797             \n",
      "GradientBoostingClassifier               0.97025              0.97203              0.39192              0.00103             \n",
      "BaggingClassifier                        0.94812              0.95105              0.05186              0.00203             \n",
      "ExtraTreesClassifier                     0.97002              0.97203              0.11665              0.01795             \n",
      "RandomForestClassifier                   0.96267              0.96503              0.20944              0.01396             \n",
      "BernoulliNB                              0.38627              0.62937              0.00199              0.0                 \n",
      "CalibratedClassifierCV                   0.93849              0.94406              0.11672              0.001               \n",
      "GaussianNB                               0.93228              0.93706              0.00096              0.001               \n",
      "LabelPropagation                         0.33012              0.40559              0.00994              0.00299             \n",
      "LabelSpreading                           0.33012              0.40559              0.01197              0.00499             \n",
      "LinearDiscriminantAnalysis               0.96952              0.97203              0.00499              0.0                 \n",
      "LinearSVC                                0.70593              0.70629              0.02597              0.0                 \n",
      "LogisticRegression                       0.95568              0.95804              0.0628               0.0                 \n",
      "LogisticRegressionCV                     0.96294              0.96503              2.10138              0.0                 \n",
      "MultinomialNB                            0.89024              0.9021               0.0                  0.0                 \n",
      "NearestCentroid                          0.88907              0.9021               0.0                  0.0                 \n",
      "NuSVC                                    0.863                0.88112              0.00701              0.00199             \n",
      "Perceptron                               0.82423              0.85315              0.00196              0.0                 \n",
      "QuadraticDiscriminantAnalysis            0.95537              0.95804              0.001                0.0                 \n",
      "SVC                                      0.93048              0.93706              0.00299              0.001               \n",
      "HistGradientBoostingClassifier           0.97743              0.97902              0.93048              0.00399             \n",
      "CategoricalNB                            Error                Error               \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print ('%-40s %-20s %-20s %-20s %-20s' % (\"Model\".center(22) ,\"F1 Score\".center(20),\"Accuracy\".center(15) ,\"Training Time\".center(15),\"Testing Time\".center(15) ))\n",
    "print ('%-40s %-20s %-20s %-20s %-20s' % (\"|____________________|\",\"____________________\",\"____________________\" ,\"____________________\",\"____________________\" ))\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine, test_size = 0.25, random_state = 0)\n",
    "\n",
    "for i in ml_list:\n",
    "    try:\n",
    "        clf=ml_list[i]\n",
    "        second=time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train=round(time.time()-second,5)\n",
    "        second=time.time()\n",
    "        predict =clf.predict(X_test)\n",
    "        test=round(time.time()-second,5)\n",
    "        f1=round(sklearn.metrics.f1_score(y_test, predict, average='macro'),5)\n",
    "        acc=round(sklearn.metrics.accuracy_score(y_test, predict),5)\n",
    "        print ('%-40s %-20s %-20s %-20s %-20s' % (i,f1,acc,train,test ))\n",
    "    except:        print ('%-40s %-20s %-20s' % (i,\"Error\",\"Error\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizing some MLs using the RandomizedSearchCV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\"RandomForestClassifier\":{\"max_depth\":np.linspace(1, 32, 32, endpoint=True),\n",
    "\"n_estimators\" : sp_randint(1, 200),\n",
    "\"max_features\": sp_randint(1, 11),\n",
    "\"min_samples_split\":sp_randint(2, 11),\n",
    "\"bootstrap\": [True, False],\n",
    "\"criterion\": [\"gini\", \"entropy\"]},\n",
    "          \n",
    "\"ExtraTreeClassifier\":{\"max_depth\":np.linspace(1, 32, 32, endpoint=True),\n",
    "\"max_features\": sp_randint(1, 11),\n",
    "\"min_samples_split\":sp_randint(2, 11),\n",
    "#\"ccp_alpha\":sp_randint(2, 11),\n",
    "#\"class_weight\":[\"balanced\", \"balanced_subsample\"],\"max_leaf_nodes\"\n",
    "\"criterion\": [\"gini\", \"entropy\"]},\n",
    "\n",
    "\"SVC\": {\"C\": np.linspace(1, 1000, 10000, endpoint=True),\n",
    "\"gamma\": np.linspace(0.1, 1000, 10000, endpoint=True)},\n",
    "          \n",
    "\"GradientBoostingClassifier\":{\"learning_rate\":np.linspace(0.0, 100, 10000, endpoint=True), #sp_randFloat(0.2,1.0),\n",
    "\"subsample\"    :np.linspace(0.0, 1, 100, endpoint=True), #sp_randFloat(0.2,1.0),\n",
    "\"n_estimators\" : sp_randInt(1, 1000),\n",
    "\"max_depth\"    : sp_randInt(1, 1000)},       \n",
    "\n",
    "          \n",
    "          \n",
    "\"DecisionTreeClassifier\" :  { 'criterion':['gini','entropy'],\n",
    "\"max_depth\":np.linspace(1, 100, 100, endpoint=True),\n",
    "\"min_samples_split\": sp_randint(2,100),#uniform(0.1,1),\n",
    " #\"min_samples_leafs\" : np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "\"max_features\" : sp_randint(1,X_train.shape[1])}    \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "NOT OPTIMIZED\n",
      "{}\n",
      "0.9578481602235678\n",
      "{}\n",
      "RandomForestClassifier()\n",
      "time=  1.186774730682373\n",
      "-------------------------------------------------------------\n",
      "OPTIMIZED\n",
      "{'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10.0, 'max_features': 6, 'min_samples_split': 5, 'n_estimators': 155}\n",
      "0.9701443875174661\n",
      "{'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10.0, 'max_features': 6, 'min_samples_split': 5, 'n_estimators': 155}\n",
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=10.0,\n",
      "                       max_features=6, min_samples_split=5, n_estimators=155)\n",
      "time=  11.857276439666748\n",
      "-------------------------------------------------------------\n",
      "ExtraTreeClassifier\n",
      "NOT OPTIMIZED\n",
      "{}\n",
      "0.924468250271697\n",
      "{}\n",
      "ExtraTreeClassifier()\n",
      "time=  0.012934684753417969\n",
      "-------------------------------------------------------------\n",
      "OPTIMIZED\n",
      "{'criterion': 'gini', 'max_depth': 10.0, 'max_features': 8, 'min_samples_split': 4}\n",
      "0.947259742276044\n",
      "{'criterion': 'gini', 'max_depth': 10.0, 'max_features': 8, 'min_samples_split': 4}\n",
      "ExtraTreeClassifier(max_depth=10.0, max_features=8, min_samples_split=4)\n",
      "time=  0.08474206924438477\n",
      "-------------------------------------------------------------\n",
      "SVC\n",
      "NOT OPTIMIZED\n",
      "{}\n",
      "0.9121720229777983\n",
      "{}\n",
      "SVC()\n",
      "time=  0.03490734100341797\n",
      "-------------------------------------------------------------\n",
      "OPTIMIZED\n",
      "{'gamma': 572.6, 'C': 63.94329432943294}\n",
      "0.6274181027790716\n",
      "{'gamma': 572.6, 'C': 63.94329432943294}\n",
      "SVC(C=63.94329432943294, gamma=572.6)\n",
      "time=  1.5508544445037842\n",
      "-------------------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "NOT OPTIMIZED\n",
      "{}\n",
      "0.9578636857630801\n",
      "{}\n",
      "GradientBoostingClassifier()\n",
      "time=  2.1522772312164307\n",
      "-------------------------------------------------------------\n",
      "OPTIMIZED\n",
      "{'learning_rate': 87.52875287528754, 'max_depth': 560, 'n_estimators': 853, 'subsample': 0.9393939393939394}\n",
      "0.9209594783418724\n",
      "{'learning_rate': 87.52875287528754, 'max_depth': 560, 'n_estimators': 853, 'subsample': 0.9393939393939394}\n",
      "GradientBoostingClassifier(learning_rate=87.52875287528754, max_depth=560,\n",
      "                           n_estimators=853, subsample=0.9393939393939394)\n",
      "time=  83.62071204185486\n",
      "-------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "NOT OPTIMIZED\n",
      "{}\n",
      "0.915618692749573\n",
      "{}\n",
      "DecisionTreeClassifier()\n",
      "time=  0.03889608383178711\n",
      "-------------------------------------------------------------\n",
      "OPTIMIZED\n",
      "{'criterion': 'entropy', 'max_depth': 36.0, 'max_features': 28, 'min_samples_split': 15}\n",
      "0.9420121099208197\n",
      "{'criterion': 'entropy', 'max_depth': 36.0, 'max_features': 28, 'min_samples_split': 15}\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=36.0, max_features=28,\n",
      "                       min_samples_split=15)\n",
      "time=  0.2752647399902344\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = cancer.data\n",
    "y= cancer.target\n",
    "models=[RandomForestClassifier(),\n",
    "ExtraTreeClassifier(),\n",
    "SVC(),\n",
    "GradientBoostingClassifier(),\n",
    "DecisionTreeClassifier()]\n",
    "for i in models:\n",
    "    \n",
    "    clf = i#(n_estimators=20)\n",
    "    second=time.time()\n",
    "    # use a full grid over all parameters\n",
    "    temp=str(i)[:-2]\n",
    "    print(temp)\n",
    "    for ii in [0,1]:\n",
    "        if ii:\n",
    "            param_dist =   opt[temp]\n",
    "            print(\"OPTIMIZED\")\n",
    "        else:\n",
    "            param_dist={}\n",
    "            print(\"NOT OPTIMIZED\")\n",
    "        n_iter_search = 10\n",
    "        random_search = RandomizedSearchCV(clf, param_distributions=param_dist)\n",
    "        random_search.fit(X, y)\n",
    "        print(random_search.best_params_)\n",
    "        print (random_search.best_score_)\n",
    "        print (random_search.best_params_)\n",
    "        print (random_search.best_estimator_)\n",
    "        print(\"time= \", (time.time()-second))\n",
    "        print(\"-------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
